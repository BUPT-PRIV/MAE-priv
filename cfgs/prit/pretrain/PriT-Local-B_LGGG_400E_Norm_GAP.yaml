output_dir: 'output/pretrain/prit_local_base_LGGG_400e_224_GAP'

# Architecture
model: pretrain_prit_local_base_LGGG_224
decoder_dim: 384
decoder_depth: 4
use_mean_pooling: True
normlize_target: True
mask_ratio: 0.75

# Train
epochs: 400
opt: adamw
lr: 0.00015 # base_lr = 1.5e-4, lr = base_lr * batch-size / 256
warmup_lr: 0.000001 # 1e-6
min_lr: 0.00001 # 1e-5
warmup_epochs: 40
batch_size: 256
hflip: 0.5

# Wandb
log_wandb: True
wandb_project: 'PriT_Pretrain'